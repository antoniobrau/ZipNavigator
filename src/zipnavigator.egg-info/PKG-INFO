Metadata-Version: 2.4
Name: zipnavigator
Version: 0.1.0
Summary: Safe navigation and batch extraction of ZIP archives with resume support.
Author-email: Antonio Brau <antonio@example.com>
License: MIT
Project-URL: Homepage, https://github.com/antoniobrau/zipnavigator
Project-URL: Repository, https://github.com/antoniobrau/zipnavigator
Project-URL: Issues, https://github.com/antoniobrau/zipnavigator/issues
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.10
Description-Content-Type: text/markdown

# ZipNavigator

## Overview

ZipNavigator is a Python utility to safely navigate and extract content from `.zip` archives. It offers filesystem-like operations (e.g., `ls`, `cd`, `pwd`, `cat`) and a robust, resumable batch-extraction iterator with CRC validation, retry policy, disk-space preflight, and persistent state saved to disk (`.zip_iter_state.json`).

**Real-world use case:** processing large datasets shipped as ZIP files (e.g., image/video corpora or nightly data drops) where you need to extract only certain file types, survive interruptions, record failures, and resume exactly where the previous run stopped.

## Features

* Filesystem-style navigation inside archives: `ls()`, `cd()`, `pwd()`, `cat()`, `exists()`, `is_dir()`, `is_file()`, `info()`.
* Resumable batch extraction via persistent state with `initialize_iterator()`, iteration (Python iterator protocol), `iterator_status()`, `reset_iterator()`, `resume_iterator()`.
* Error policy: `on_error="skip" | "abort"`, with `max_retries` per file.
* Optional integrity checks with `validate_crc=True`.
* Disk-space preflight for each batch.
* Safe path handling to prevent Zip Slip (rejects absolute paths, drive letters, and `..` traversal).
* Python 3.10+ and standard library only (no external dependencies).

## Installation

```bash
# Clone and enter the repository
git clone https://github.com/antoniobrau/zipnavigator.git
cd zipnavigator

# (Recommended) Create a virtual environment
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate

# Install the package
pip install .

# Alternatively, for editable development installs:
# pip install -e .
```

## Usage

### Basic navigation

```python
from zipnavigator import ZipNavigator

nav = ZipNavigator("data/archive.zip")

print(nav.pwd())             # "/"
print(nav.ls())              # top-level entries
nav.cd("docs/")              # change directory inside the zip
print(nav.ls())              # list inside docs/
print(nav.exists("README.txt"))
print(nav.is_file("README.txt"))
print(nav.info("README.txt"))  # metadata (size, compression, CRC, etc.)

text = nav.cat("README.txt")   # read text file (UTF-8 by default)
print(text[:200])
```

### Resumable batch extraction (iterator)

```python
from zipnavigator import ZipNavigator
from pathlib import Path

nav = ZipNavigator("data/dataset.zip")

# Optionally narrow the working base before initializing the iterator
nav.cd("images/")

nav.initialize_iterator(
    output_dir="work",                 # parent folder for extraction
    batch_size=50,                     # batch size
    extract_subdir="extracted_zip",    # extraction subfolder
    reset=True,                        # start fresh (clears previous state for this run)
    seed=42,                           # shuffle order deterministically
    extensions=[".jpg", ".png"],       # filter by extension (optional)
    on_error="skip",                   # or "abort"
    max_retries=2,
    validate_crc=True                  # integrity check (slower, safer)
)

# Each iteration extracts one batch and returns absolute paths of extracted files
for extracted_paths in nav:
    print("Extracted:", extracted_paths)

    # You can inspect progress at any time
    state = nav.iterator_status()
    print("Done:", state["extracted_so_far"], "Remaining:", state["remaining"])
```

### Resuming a previous run

```python
from zipnavigator import ZipNavigator

# Re-open the same archive and resume from saved state
nav = ZipNavigator("data/dataset.zip")
nav.resume_iterator(
    output_dir="work",
    extract_subdir="extracted_zip"
)

for extracted_paths in nav:
    print("Resumed batch:", extracted_paths)
```

### Resetting iterator state

```python
# Clear iterator state and temporary extraction files for a new configuration/run
nav.reset_iterator()
```

## Examples

### Example: selective extraction to a custom folder structure

```python
from zipnavigator import ZipNavigator
from pathlib import Path

nav = ZipNavigator("data/bundle.zip")
nav.cd("payload/")

nav.initialize_iterator(
    output_dir="out",
    batch_size=100,
    extract_subdir="batch",
    reset=True,
    extensions=[".csv"],
    on_error="skip",
    max_retries=1,
    validate_crc=False
)

for batch_paths in nav:
    # batch_paths are absolute filesystem paths under out/batch/
    for p in batch_paths:
        # You can move or post-process files here
        # e.g., send to a data warehouse, parse CSV, etc.
        print("Ready:", p)

    st = nav.iterator_status()
    print(f"Progress: {st['extracted_so_far']}/{st['total_files']}  Failed so far: {st['failed_so_far']}")
```

### Example: listing and inspecting entries before extraction

```python
from zipnavigator import ZipNavigator

nav = ZipNavigator("data/archive.zip")
print(nav.ls(recursive=True)[:10])      # preview first 10 entries
meta = nav.info("docs/manual.pdf")      # get compressed/uncompressed sizes, CRC, compression type
print(meta)
```

## Contributing

1. Fork the repository and create a feature branch.
2. Keep changes focused and add tests when applicable.
3. Ensure code is formatted and linted.
4. Open a pull request with a clear description, rationale, and, if relevant, benchmarks or before/after diagnostics.

## License

MIT. See the `LICENSE` file in the repository root.
